# RAG
It is a technique where an LLM is given external knowledge at runtime so it can generate accurate, context-aware answers.
